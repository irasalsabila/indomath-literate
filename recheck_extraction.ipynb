{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder and file path for evaluation results\n",
    "folder = 'mgsm/results_deepseekr1'  # <-- Change to the specific folder you want\n",
    "filename = f'{folder}/final_result.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results dataframe\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "# Set tolerance for numerical comparison\n",
    "tolerance = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer(text):\n",
    "    \"\"\"\n",
    "    Extract a numerical answer from the given text, handling boxed formats, \n",
    "    different localizations (e.g., commas, periods), and fallback strategies.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text containing the numerical answer.\n",
    "    \n",
    "    Returns:\n",
    "        float or None: The extracted numerical answer, or None if not found.\n",
    "    \"\"\"\n",
    "    def parse_locale_number(number_str):\n",
    "        \"\"\"\n",
    "        Handle different number formats, such as '1.234,56' vs '1,234.56'.\n",
    "        \"\"\"\n",
    "        if '.' in number_str and ',' in number_str:\n",
    "            if number_str.find('.') < number_str.find(','):\n",
    "                return number_str.replace('.', '').replace(',', '.')\n",
    "            else:\n",
    "                return number_str.replace(',', '')\n",
    "        elif '.' in number_str and not ',' in number_str:\n",
    "            parts = number_str.split('.')\n",
    "            if all(len(p) == 3 for p in parts[1:]):  # likely thousands separator\n",
    "                return number_str.replace('.', '')\n",
    "        elif ',' in number_str and not '.' in number_str:\n",
    "            return number_str.replace(',', '')\n",
    "        return number_str  # fallback\n",
    "\n",
    "    try:\n",
    "        # Extract from boxed expressions like \\boxed{123}\n",
    "        matches = re.findall(r'\\\\?boxed\\{.*?([\\d.,]+).*?\\}', text)\n",
    "        if matches:\n",
    "            number_str = matches[-1]\n",
    "            number_str = re.sub(r'[^\\d.,-]', '', number_str)\n",
    "            number_str = parse_locale_number(number_str)\n",
    "            return float(number_str)\n",
    "\n",
    "        # Fallback: extract last number appearing in text\n",
    "        numbers = re.findall(r'[-+]?\\d{1,3}(?:[.,]\\d{3})*(?:[.,]\\d+)?|\\d+', text)\n",
    "        if numbers:\n",
    "            number_str = re.sub(r'[^\\d.,-]', '', numbers[-1])\n",
    "            number_str = parse_locale_number(number_str)\n",
    "            return float(number_str)\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.info(f\"Error extracting answer from text: {text}\\nException: {e}\")\n",
    "        return None\n",
    "\n",
    "    logging.info(f\"No valid answer found in text: {text}\")\n",
    "    return None\n",
    "\n",
    "def check_correct(pred, actual, tol=tolerance):\n",
    "    \"\"\"\n",
    "    Check if the predicted number matches the actual answer within a tolerance.\n",
    "\n",
    "    Args:\n",
    "        pred (float): Predicted number.\n",
    "        actual (float): Actual answer.\n",
    "        tol (float): Tolerance for equality check.\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if within tolerance, else False.\n",
    "    \"\"\"\n",
    "    if pd.notnull(pred):\n",
    "        return abs(actual - pred) < tol\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numerical answers from model outputs\n",
    "df[\"gen_answer2\"] = df[\"gen_text\"].apply(extract_answer)\n",
    "\n",
    "# Check correctness based on re-extracted answers\n",
    "df[\"is_correct2\"] = df.apply(lambda row: check_correct(row[\"gen_answer2\"], row[\"answer_number\"]), axis=1)\n",
    "\n",
    "# Show comparison of original and rechecked results\n",
    "df[[\"q_no\", \"lang\", \"answer_number\", \"gen_answer\", \"is_correct\", \"gen_answer2\", \"is_correct2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_comparison_stats(comparison_stats):\n",
    "    \"\"\"\n",
    "    Transform comparison statistics into nicely formatted correctness and incorrectness tables.\n",
    "\n",
    "    Args:\n",
    "        comparison_stats (pd.DataFrame): Dataframe containing aggregated statistics.\n",
    "    \n",
    "    Returns:\n",
    "        (pd.DataFrame, pd.DataFrame): Correctness and Incorrectness summary tables.\n",
    "    \"\"\"\n",
    "    total_initial_correct = comparison_stats['original_correct'].sum()\n",
    "    total_revision_correct = comparison_stats['revised_correct'].sum()\n",
    "    total_initial_incorrect = comparison_stats['original_incorrect'].sum()\n",
    "    total_revision_incorrect = comparison_stats['revised_incorrect'].sum()\n",
    "\n",
    "    tables = {}\n",
    "    for table_name, cols in zip(['correctness', 'incorrectness'], \n",
    "                                [['original_correct', 'revised_correct'], ['original_incorrect', 'revised_incorrect']]):\n",
    "        data = {'type': ['initial', 'recheck']}\n",
    "        \n",
    "        for lang in comparison_stats['lang']:\n",
    "            data[lang] = [\n",
    "                comparison_stats.loc[comparison_stats['lang'] == lang, cols[0]].values[0],\n",
    "                comparison_stats.loc[comparison_stats['lang'] == lang, cols[1]].values[0]\n",
    "            ]\n",
    "        \n",
    "        # Add total sums across languages\n",
    "        data['total'] = [\n",
    "            sum(comparison_stats[cols[0]]),\n",
    "            sum(comparison_stats[cols[1]])\n",
    "        ]\n",
    "        \n",
    "        tables[table_name] = pd.DataFrame(data)\n",
    "\n",
    "    return tables['correctness'], tables['incorrectness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_stats = df.groupby('lang')[['is_correct', 'is_correct2']].agg(\n",
    "    original_correct=('is_correct', lambda x: sum(x == True)),\n",
    "    original_incorrect=('is_correct', lambda x: sum(x == False)),\n",
    "    revised_correct=('is_correct2', lambda x: sum(x == True)),\n",
    "    revised_incorrect=('is_correct2', lambda x: sum(x == False))\n",
    ").reset_index()\n",
    "\n",
    "# Transform to readable tables\n",
    "correctness_table, incorrectness_table = transform_comparison_stats(comparison_stats)\n",
    "\n",
    "print('correctness_table')\n",
    "display(correctness_table)\n",
    "\n",
    "print('incorrectness_table')\n",
    "display(incorrectness_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df[\"is_correct2\"] == False  # Only focus on rows that were incorrect initially\n",
    "\n",
    "# Apply extraction on self-revision texts\n",
    "df.loc[mask, \"revised_answer2\"] = df.loc[mask, \"self_revision\"].apply(extract_answer)\n",
    "\n",
    "# Recheck correctness after revision extraction\n",
    "df.loc[mask, \"is_correct_rev2\"] = df.loc[mask].apply(\n",
    "    lambda row: check_correct(row[\"revised_answer2\"], row[\"answer_number\"], tol=tolerance),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If already correct, mark revision as correct\n",
    "df.loc[~mask, \"revised_answer2\"] = None\n",
    "df.loc[~mask, \"is_correct_rev2\"] = True\n",
    "\n",
    "# Create a dataframe to inspect revision rechecking\n",
    "df_revision_check = df[mask][[\n",
    "    \"q_no\", \"lang\", \"answer_number\", \n",
    "    \"gen_answer2\", \"is_correct2\", \n",
    "    \"revised_answer2\", \"is_correct_rev2\"\n",
    "]]\n",
    "\n",
    "df_revision_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_stats = df.groupby('lang')[['is_correct2', 'is_correct_rev2']].agg(\n",
    "    original_correct=('is_correct2', lambda x: sum(x == True)),\n",
    "    original_incorrect=('is_correct2', lambda x: sum(x == False)),\n",
    "    revised_correct=('is_correct_rev2', lambda x: sum(x == True)),\n",
    "    revised_incorrect=('is_correct_rev2', lambda x: sum(x == False))\n",
    ").reset_index()\n",
    "\n",
    "correctness_table, incorrectness_table = transform_comparison_stats(comparison_stats)\n",
    "\n",
    "print('correctness_table')\n",
    "display(correctness_table)\n",
    "\n",
    "print('incorrectness_table')\n",
    "display(incorrectness_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 'X'  # Prefix for saving\n",
    "df.to_csv(f'{folder}/{X}final_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlg804",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
